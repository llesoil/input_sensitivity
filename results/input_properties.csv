Name&doi&Description (extracted from the original papers)
Banding Mean Opinion Score&&Banding is a common video artifact caused by compressinglow texture regions with coarse quantization. Relatively fewprevious attempts exist to address banding and none incorpo-rate subjective testing for calibrating the measurement. In thispaper, we propose a novel metric that incorporates both edgelength and contrast across the edge to measure video band-ing. We further introduce both reference and non-referencemetrics. Our results demonstrate that the new metrics have avery high correlation with subjective assessment and certainlyoutperforms Peak Signal Noise Ratio, Structural SIMilarity, and Video Quality Measurement.
Self-reference based LEarning-free Evaluator of Quality Mean Opinion Score&&No-Reference  (NR)  video  quality  assessment  (VQA)  models  are  gaining  popularity  as they  offer  scope  for  broader applicability to user-uploaded video-centric services such as YouTube and Facebook, where the pristine references are unavailable. However, there are few, well-performing NR-VQA models owing to the difficulty of the problem.  We propose a novel NR video quality predictor that solely relies on the ‘quality-aware’  natural  statistical  models  in  the  space-time domain. The proposed quality predictor called Self-reference based LEarning free Evaluator of Quality (SLEEQ) consists of  three  components:  feature  extraction  in  the  spatial  and temporal domains, motion-based feature fusion, and spatial-temporal feature pooling to derive a single quality score for agiven video. SLEEQ achieves higher than 0.9 correlation with the subjective video quality scores on tested public databases and thus outperforms the existing NR VQA models.
Height&&Vertical resolution of the video (number of pixels) 
Width&&Horizontal resolution of the video (number of pixels) 
Spatial complexity&&In general spatial detail in a frame is correlated with the bits used to encode that frame, when encoded as an Intra frame. Over a 20 sec chunk therefore, we calculate our spatial complexity feature as the average I frame bitrate normalized by the frame area.
Color complexity&&We define color complexity metric as the ratio between the average of mean Sum of Squared Error (SSE) in U and V channels to the mean SSE in Y channel (obtained from Peak Signal Noise Ratio measurements). A high score means complex color variations in the frame and a low score usually means a gray image with only luminance changes
Temporal complexity&&The number of bits used to encode a P frame is proportional to the temporal complexity of a sequence. However visual material with high spatial complexity (large I frames) tends to have large P frames because small motion compensation errors lead to large residuals. To decouple this effect, we normalize the P frame bits by taking a ratio with the I frame bits, as a fair indicator of temporal complexity.
Chunk complexity&&To explore quality variation within the video, we measured the standard deviation of compressed bitrates among all 1 sec chunks (also normalized by the frame size). If the scene is static or has a smooth motion, the chunk variation score should be close to 0, and the row sum map has no sudden changes. Multiple scene changes within a video (common in Gaming videos) will lead to multiple different regions on the row sum map.
